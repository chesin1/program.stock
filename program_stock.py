# ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import yfinance as yf
import pandas as pd
import requests
import xml.etree.ElementTree as ET
from pandas_datareader import data as web
from datetime import datetime
import pytz
import os
from bs4 import BeautifulSoup

# âœ… PER/PBR ìºì‹œ (ë„¤ì´ë²„ìš©)
CACHE_FILE = "per_pbr_cache.csv"
def save_to_cache(ticker, per, pbr):
    try:
        df = pd.read_csv(CACHE_FILE) if os.path.exists(CACHE_FILE) else pd.DataFrame(columns=["ticker", "per", "pbr"])
        df = df[df["ticker"] != ticker]
        df = pd.concat([df, pd.DataFrame([[ticker, per, pbr]], columns=["ticker", "per", "pbr"])], ignore_index=True)
        df.to_csv(CACHE_FILE, index=False, encoding='utf-8-sig')
    except: pass

def load_from_cache(ticker):
    try:
        if not os.path.exists(CACHE_FILE): return "ìˆ˜ì§‘ ì‹¤íŒ¨", "ìˆ˜ì§‘ ì‹¤íŒ¨"
        df = pd.read_csv(CACHE_FILE)
        row = df[df["ticker"] == ticker]
        return row.iloc[0]["per"], row.iloc[0]["pbr"] if not row.empty else ("ìˆ˜ì§‘ ì‹¤íŒ¨", "ìˆ˜ì§‘ ì‹¤íŒ¨")
    except:
        return "ìˆ˜ì§‘ ì‹¤íŒ¨", "ìˆ˜ì§‘ ì‹¤íŒ¨"

# âœ… í•´ì„ í•¨ìˆ˜ë“¤
def interpret_per(val):
    try: val = float(str(val).replace(',', '')); return "ë§¤ìˆ˜" if val < 10 else "ì¤‘ë¦½" if val <= 25 else "ë§¤ë„"
    except: return "í•´ì„ë¶ˆê°€"

def interpret_pbr(val):
    try: val = float(str(val).replace(',', '')); return "ë§¤ìˆ˜" if val < 1 else "ì¤‘ë¦½" if val <= 3 else "ë§¤ë„"
    except: return "í•´ì„ë¶ˆê°€"

def interpret_ratio(val, low, high):
    try: val = float(val); return "ë§¤ìˆ˜" if val < low else "ì¤‘ë¦½" if val <= high else "ë§¤ë„"
    except: return "í•´ì„ë¶ˆê°€"

def interpret_rsi(val):
    try: return "ë§¤ìˆ˜" if val < 30 else "ì¤‘ë¦½" if val <= 70 else "ë§¤ë„"
    except: return "í•´ì„ë¶ˆê°€"

def interpret_moving_avg(current, ma):
    try:
        current, ma = float(current), float(ma)
        diff = (current - ma) / ma * 100
        return f"{ma:.2f} (ë§¤ìˆ˜)" if diff > 1 else f"{ma:.2f} (ë§¤ë„)" if diff < -1 else f"{ma:.2f} (ì¤‘ë¦½)"
    except: return "ìˆ˜ì§‘ ì‹¤íŒ¨"

def interpret_dividend_yield(val):
    try: val = float(val); val *= 100 if val < 1 else 1; return "ë§¤ìˆ˜" if val >= 3 else "ì¤‘ë¦½" if val >= 1 else "ë§¤ë„"
    except: return "í•´ì„ë¶ˆê°€"

def interpret_profit_margin(val):
    try: val = float(val); val *= 100 if val < 1 else 1; return "ë§¤ìˆ˜" if val >= 15 else "ì¤‘ë¦½" if val >= 5 else "ë§¤ë„"
    except: return "í•´ì„ë¶ˆê°€"

def interpret_forward_pe(val):
    try: val = float(val); return "ë§¤ìˆ˜" if val < 10 else "ì¤‘ë¦½" if val <= 25 else "ë§¤ë„"
    except: return "í•´ì„ë¶ˆê°€"

def interpret_52w_change(val):
    try: val = float(val); val *= 100 if abs(val) < 1 else 1; return "ë§¤ìˆ˜" if val >= 20 else "ì¤‘ë¦½" if val >= -10 else "ë§¤ë„"
    except: return "í•´ì„ë¶ˆê°€"

def format_market_cap(val):
    try:
        val = int(val)
        return f"{val / 1_0000_0000_0000:.1f}ì¡°" if val >= 1_0000_0000_0000 else \
               f"{val / 1_0000_0000:.0f}ì–µ" if val >= 1_0000_0000 else \
               f"{val / 1_0000:.0f}ë§Œ" if val >= 1_0000 else str(val)
    except: return "ìˆ˜ì§‘ ì‹¤íŒ¨"

# âœ… RSI ê³„ì‚°
def calculate_rsi(close, period=14):
    delta = close.diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.rolling(period).mean()
    avg_loss = loss.rolling(period).mean()
    rs = avg_gain / avg_loss
    return round(100 - (100 / (1 + rs)).iloc[-1], 2)

def get_per_pbr_naver(ticker):
    code = ticker.split('.')[0]
    url = f"https://finance.naver.com/item/main.naver?code={code}"

    try:
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        res.raise_for_status()

        soup = BeautifulSoup(res.text, 'html.parser')
        per_tag = soup.select_one('em#_per')
        pbr_tag = soup.select_one('em#_pbr')

        per = per_tag.text.strip() if per_tag else "ìˆ˜ì§‘ ì‹¤íŒ¨"
        pbr = pbr_tag.text.strip() if pbr_tag else "ìˆ˜ì§‘ ì‹¤íŒ¨"

        save_to_cache(ticker, per, pbr)
        return per, pbr
    except:
        return load_from_cache(ticker)

# âœ… íŒ¨ë”© í•¨ìˆ˜ (ê±°ì‹œì§€í‘œìš©)
def pad_df(df, target_cols):
    pad_cols = len(target_cols) - df.shape[1]
    for i in range(pad_cols): df[f"ë¹ˆì¹¸{i+1}"] = ""
    return df

# âœ… ì£¼ì‹ ë¦¬ìŠ¤íŠ¸ (ìƒ˜í”Œ)
kr_stocks = {    '005930.KS': 'ì‚¼ì„±ì „ì', '000660.KS': 'SKí•˜ì´ë‹‰ìŠ¤', '373220.KS': 'LGì—ë„ˆì§€ì†”ë£¨ì…˜',
    '207940.KS': 'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', '005935.KS': 'ì‚¼ì„±ë¬¼ì‚°', '005380.KS': 'í˜„ëŒ€ì°¨',
    '000270.KS': 'ê¸°ì•„', '005490.KS': 'POSCOí™€ë”©ìŠ¤', '035420.KS': 'LGí™”í•™', '035720.KS': 'NAVER',
    '051910.KS': 'ì‚¼ì„±SDI', '012330.KS': 'í˜„ëŒ€ëª¨ë¹„ìŠ¤', '066570.KS': 'LGì „ì', '055550.KS': 'ì‹ í•œì§€ì£¼',
    '105560.KS': 'KBê¸ˆìœµ', '086790.KS': 'í•˜ë‚˜ê¸ˆìœµì§€ì£¼', '032640.KS': 'ì‚¼ì„±ìƒëª…', '015760.KS': 'í•œêµ­ì „ë ¥',
    '003490.KS': 'ëŒ€í•œí•­ê³µ', '011780.KS': 'HMM', '096770.KS': 'SKì´ë…¸ë² ì´ì…˜', '005180.KS': 'KT&G',
    '010950.KS': 'S-Oil', '032830.KS': 'ìš°ë¦¬ê¸ˆìœµì§€ì£¼', '009150.KS': 'ì‚¼ì„±ì „ê¸°', '259960.KS': 'í¬ë˜í”„í†¤',
    '251270.KS': 'ë„·ë§ˆë¸”', '036570.KS': 'ì—”ì”¨ì†Œí”„íŠ¸', '000220.KS': 'ê³ ë ¤ì•„ì—°', '090430.KS': 'ì•„ëª¨ë ˆí¼ì‹œí”½',
    '034220.KS': 'LGë””ìŠ¤í”Œë ˆì´', '000240.KS': 'í•œêµ­íƒ€ì´ì–´', '042670.KS': 'í•œêµ­í•­ê³µìš°ì£¼', '010120.KS': 'LS ELECTRIC',
    '019570.KS': 'í•œë¯¸ì‚¬ì´ì–¸ìŠ¤', '024110.KS': 'SK', '007070.KS': 'GSë¦¬í…Œì¼', '139480.KS': 'ì´ë§ˆíŠ¸',
    '011170.KS': 'ë¡¯ë°ì¼€ë¯¸ì¹¼', '004020.KS': 'í•œí™”', '067010.KS': 'ë¡¯ë°ì‡¼í•‘', '006800.KS': 'ì‚¼ì²œë¦¬',
    '068270.KS': 'ì…€íŠ¸ë¦¬ì˜¨', '033780.KS': 'í•œêµ­ê°€ìŠ¤ê³µì‚¬', '000810.KS': 'ì‹ ì„¸ê³„', '007310.KS': 'ëŒ€ìš°ê±´ì„¤',
    '086280.KS': 'ì‚¼ì„±ì¤‘ê³µì—…', '003030.KS': 'í•œêµ­í•­ê³µìš°ì£¼', '000720.KS': 'SKë„¤íŠ¸ì›ìŠ¤',
    '023530.KS': 'ì•„ëª¨ë ˆí¼ì‹œí”½', '003060.KS': 'ëŒ€ìš°ì¡°ì„ í•´ì–‘', '027410.KS': 'í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤'}
us_stocks = {'AAPL': 'Apple', 'MSFT': 'Microsoft', 'GOOG': 'Alphabet', 'AMZN': 'Amazon', 'META': 'Meta Platforms',
    'TSLA': 'Tesla', 'BRK-B': 'Berkshire Hathaway', 'V': 'Visa', 'JNJ': 'Johnson & Johnson', 'UNH': 'UnitedHealth',
    'XOM': 'Exxon Mobil', 'JPM': 'JPMorgan Chase', 'PG': 'Procter & Gamble', 'MA': 'Mastercard', 'HD': 'Home Depot',
    'CVX': 'Chevron', 'LLY': 'Eli Lilly', 'PFE': 'Pfizer', 'KO': 'Coca-Cola', 'PEP': 'PepsiCo', 'MRK': 'Merck',
    'ABBV': 'AbbVie', 'WMT': 'Walmart', 'INTC': 'Intel', 'CSCO': 'Cisco', 'CMCSA': 'Comcast', 'QCOM': 'Qualcomm',
    'AVGO': 'Broadcom', 'TMO': 'Thermo Fisher', 'NKE': 'Nike', 'ORCL': 'Oracle', 'TXN': 'Texas Instruments',
    'IBM': 'IBM', 'CRM': 'Salesforce', 'ADBE': 'Adobe', 'COST': 'Costco', 'AMGN': 'Amgen', 'INTU': 'Intuit',
    'NFLX': 'Netflix', 'AMD': 'AMD', 'SBUX': 'Starbucks', 'GILD': 'Gilead Sciences', 'BKNG': 'Booking Holdings',
    'PYPL': 'PayPal', 'GE': 'General Electric', 'MMM': '3M', 'CVS': 'CVS Health', 'F': 'Ford', 'MRNA': 'Moderna'}
all_stocks = {**kr_stocks, **us_stocks}

# âœ… ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘
results = []
for ticker, name in all_stocks.items():
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        hist = stock.history(period="1mo")
        h2 = stock.history(period="5d")
        if hist.empty or len(h2) < 2: continue
        today = h2['Close'].iloc[-1]
        prev = h2['Close'].iloc[-2]
        change = today - prev
        rate = round(change / prev * 100, 2)

        is_kr = ticker.endswith('.KS') or ticker.endswith('.KQ')
        per, pbr = get_per_pbr_naver(ticker) if is_kr else (
            info.get("trailingPE", "ìˆ˜ì§‘ ì‹¤íŒ¨"),
            info.get("priceToBook", "ìˆ˜ì§‘ ì‹¤íŒ¨")
        )

        roe = info.get("returnOnEquity", "ìˆ˜ì§‘ ì‹¤íŒ¨")
        debt = info.get("debtToEquity", "ìˆ˜ì§‘ ì‹¤íŒ¨")
        div = info.get("dividendYield", "ìˆ˜ì§‘ ì‹¤íŒ¨")
        margin = info.get("profitMargins", "ìˆ˜ì§‘ ì‹¤íŒ¨")
        fpe = info.get("forwardPE", "ìˆ˜ì§‘ ì‹¤íŒ¨")
        chg52 = info.get("52WeekChange", "ìˆ˜ì§‘ ì‹¤íŒ¨")
        volume = info.get("volume", "ìˆ˜ì§‘ ì‹¤íŒ¨")
        mcap = format_market_cap(info.get("marketCap", "ìˆ˜ì§‘ ì‹¤íŒ¨"))
        rsi = calculate_rsi(hist["Close"])
        ma5 = round(hist['Close'].rolling(5).mean().iloc[-1], 2)
        ma20 = round(hist['Close'].rolling(20).mean().iloc[-1], 2)

        results.append({
            "ì¢…ëª©ëª…": name, "í‹°ì»¤": ticker,
            "ë‹¹ì¼ì¢…ê°€": round(today, 2), "ì „ë‚ ì¢…ê°€": round(prev, 2), "ë³€í™”ëŸ‰": round(change, 2), "ë³€í™”ìœ¨(%)": rate,
            "PER": per, "PER_í•´ì„": interpret_per(per),
            "PBR": pbr, "PBR_í•´ì„": interpret_pbr(pbr),
            "ROE": roe, "ROE_í•´ì„": interpret_ratio(roe, 0.1, 0.2),
            "Debt/Equity": debt, "Debt/Equity_í•´ì„": interpret_ratio(debt, 50, 150),
            "Dividend Yield": div, "ë°°ë‹¹ë¥ _í•´ì„": interpret_dividend_yield(div),
            "Profit Margin": margin, "ì´ìµë¥ _í•´ì„": interpret_profit_margin(margin),
            "Forward PE": fpe, "Forward PE_í•´ì„": interpret_forward_pe(fpe),
            "52ì£¼ ë³€í™”ìœ¨": chg52, "52ì£¼ í•´ì„": interpret_52w_change(chg52),
            "RSI": rsi, "RSI_í•´ì„": interpret_rsi(rsi),
            "5ì¼ ì´í‰ì„ ": interpret_moving_avg(today, ma5),
            "20ì¼ ì´í‰ì„ ": interpret_moving_avg(today, ma20),
            "ê±°ë˜ëŸ‰": volume, "ì‹œê°€ì´ì•¡": mcap
        })

    except Exception as e:
        print(f"âŒ {name} ì—ëŸ¬ ë°œìƒ: {e}")

stock_df = pd.DataFrame(results)

# âœ… ë¯¸êµ­ ê±°ì‹œì§€í‘œ
def get_us_macro_df_and_print():
    us_indicators = {
        'GDP': 'êµ­ë‚´ì´ìƒì‚°', 'FEDFUNDS': 'ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬', 'UNRATE': 'ì‹¤ì—…ë¥ ', 'CPIAUCNS': 'ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜',
        'CPILFESL': 'ê·¼ì› CPI', 'PCE': 'ê°œì¸ì†Œë¹„ì§€ì¶œ', 'UMCSENT': 'ì†Œë¹„ìì‹¬ë¦¬ì§€ìˆ˜',
        'ICSA': 'ì‹ ê·œ ì‹¤ì—…ìˆ˜ë‹¹ì²­êµ¬ê±´ìˆ˜', 'GS10': '10ë…„ êµ­ì±„ ìˆ˜ìµë¥ ', 'USSLIND': 'ê²½ê¸° ì„ í–‰ì§€ìˆ˜'
    }
    print("\nğŸ“Š [ë¯¸êµ­ ê±°ì‹œì§€í‘œ Top 10 - FRED]\n")
    rows = []
    for code, name in us_indicators.items():
        try:
            df = web.DataReader(code, 'fred', '2010-01-01', datetime.today()).dropna()
            latest_date = df.index[-1].strftime('%Y-%m-%d')
            latest_value = df.iloc[-1, 0]
            print(f"ğŸ”¹ {name} [{latest_date}]: {latest_value}")
            rows.append([name, code, latest_date, latest_value])
        except Exception as e:
            print(f"âŒ {name} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            rows.append([name, code, "ìˆ˜ì§‘ ì‹¤íŒ¨", "ìˆ˜ì§‘ ì‹¤íŒ¨"])
    return pd.DataFrame(rows, columns=["ì§€í‘œëª…", "ì½”ë“œ", "ë‚ ì§œ", "ê°’"])

# âœ… í•œêµ­ ê±°ì‹œì§€í‘œ
def get_korea_macro_df_and_print():
    print("\nğŸ“Š [í•œêµ­ ê±°ì‹œì§€í‘œ - ECOS ì£¼ìš”ì§€í‘œ 10ì„ ]\n")
    API_KEY = 'VADVWXGUAJ1D7O7H9PKX'
    url = f'https://ecos.bok.or.kr/api/KeyStatisticList/{API_KEY}/xml/kr/1/100'
    res = requests.get(url)
    root = ET.fromstring(res.content)

    keywords = ["ê¸°ì¤€ê¸ˆë¦¬", "ì½œê¸ˆë¦¬", "ìˆ˜ì‹ ê¸ˆë¦¬", "ëŒ€ì¶œê¸ˆë¦¬", "ê°€ê³„ì‹ ìš©", "M2", "í™˜ìœ¨(ì¢…ê°€)", "GDP", "ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜", "ì‹¤ì—…ë¥ "]

    rows = []
    idx = 1
    for row in root.findall('.//row'):
        title = row.findtext('KEYSTAT_NAME', default="N/A").strip()
        if any(k in title for k in keywords):
            time = row.findtext('TIME', default="N/A").strip()
            value = row.findtext('DATA_VALUE', default="N/A").strip()
            unit = row.findtext('UNIT_NAME', default="").strip()
            print(f"{idx:>2}. {title} [{time}]: {value} {unit}")
            rows.append([title, time, value, unit])
            idx += 1
        if idx > 10: break
    return pd.DataFrame(rows, columns=["ì§€í‘œëª…", "ë‚ ì§œ", "ê°’", "ë‹¨ìœ„"])

# âœ… CSV íŒŒì¼ ì €ì¥
filename = "data/stock_price.csv"

us_df = get_us_macro_df_and_print()
kr_df = get_korea_macro_df_and_print()

blank = pd.DataFrame([[""] * stock_df.shape[1]], columns=stock_df.columns)
us_title = pd.DataFrame([["[ë¯¸êµ­ ê±°ì‹œì§€í‘œ]"] + [""] * (stock_df.shape[1] - 1)], columns=stock_df.columns)
kr_title = pd.DataFrame([["[í•œêµ­ ê±°ì‹œì§€í‘œ]"] + [""] * (stock_df.shape[1] - 1)], columns=stock_df.columns)
us_df_padded = pad_df(us_df.copy(), stock_df.columns)
kr_df_padded = pad_df(kr_df.copy(), stock_df.columns)

final_df = pd.concat([stock_df, blank, us_title, us_df_padded, blank, kr_title, kr_df_padded], ignore_index=True)
final_df = final_df.dropna(axis=1, how='all')  # âš ï¸ ì—¬ê¸°ì„œ 'how="any"' ëŒ€ì‹  'how="all"'ë„ ê³ ë ¤ ê°€ëŠ¥
os.makedirs(os.path.dirname(filename), exist_ok=True)
final_df.to_csv(filename, index=False, encoding='utf-8-sig')
print(f"\nâœ… ìµœì¢… CSV ì €ì¥ ì™„ë£Œ â†’ {filename}")

# âœ… ì—‘ì…€ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (í•˜ìœ„ 20ì¤„)
# âœ… ëª¨ë“  ì—´ ì¶œë ¥ ì„¤ì • (ì—´ ìƒëµ ë°©ì§€)
pd.set_option('display.max_columns', None)

# âœ… CSV ì €ì¥ í›„ ë¯¸ë¦¬ë³´ê¸° (NaN í¬í•¨, ì¤„ë°”ê¿ˆ ì—†ì´ ì „ì²´ ì¶œë ¥)
print("\nğŸ“„ [ë¯¸ë¦¬ë³´ê¸° - ìƒìœ„ 2ì¤„]")
print(final_df.tail(20).to_string(index=False))
